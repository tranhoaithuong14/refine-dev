# Kiáº¿n trÃºc vÃ  Design Patterns cá»§a useImport Hook

## 1. VAI TRÃ’ TRONG Há»† THá»NG

### 1.1 Vá»‹ trÃ­ trong Refine Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    REFINE FRAMEWORK                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚       IMPORT/EXPORT SYSTEM (DATA UTILITIES)       â”‚  â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚  â”‚                                                   â”‚  â”‚
â”‚  â”‚  useImport âœ… (THIS HOOK - COUNTERPART!)         â”‚  â”‚
â”‚  â”‚    â†’ Import CSV files to backend                 â”‚  â”‚
â”‚  â”‚         â”‚                                         â”‚  â”‚
â”‚  â”‚         â”œâ”€â”€â†’ PARSE CSV:                          â”‚  â”‚
â”‚  â”‚         â”‚     - PapaParse library                â”‚  â”‚
â”‚  â”‚         â”‚     - Headers â†’ Object keys            â”‚  â”‚
â”‚  â”‚         â”‚     - Rows â†’ Array of objects          â”‚  â”‚
â”‚  â”‚         â”‚                                         â”‚  â”‚
â”‚  â”‚         â”œâ”€â”€â†’ TRANSFORM:                          â”‚  â”‚
â”‚  â”‚         â”‚     - mapData function                 â”‚  â”‚
â”‚  â”‚         â”‚     - Clean/validate data              â”‚  â”‚
â”‚  â”‚         â”‚     - Format for backend               â”‚  â”‚
â”‚  â”‚         â”‚                                         â”‚  â”‚
â”‚  â”‚         â”œâ”€â”€â†’ BATCH PROCESSING:                   â”‚  â”‚
â”‚  â”‚         â”‚     - Configurable batch size          â”‚  â”‚
â”‚  â”‚         â”‚     - Sequential execution             â”‚  â”‚
â”‚  â”‚         â”‚     - Progress tracking                â”‚  â”‚
â”‚  â”‚         â”‚                                         â”‚  â”‚
â”‚  â”‚         â”œâ”€â”€â†’ MUTATIONS:                          â”‚  â”‚
â”‚  â”‚         â”‚     - create (batchSize=1)             â”‚  â”‚
â”‚  â”‚         â”‚     - createMany (batchSize>1)         â”‚  â”‚
â”‚  â”‚         â”‚     - Error handling per batch         â”‚  â”‚
â”‚  â”‚         â”‚                                         â”‚  â”‚
â”‚  â”‚         â””â”€â”€â†’ CALLBACKS:                          â”‚  â”‚
â”‚  â”‚               - onProgress â†’ Track upload        â”‚  â”‚
â”‚  â”‚               - onFinish â†’ Results summary       â”‚  â”‚
â”‚  â”‚                                                   â”‚  â”‚
â”‚  â”‚  Companion to:                                   â”‚  â”‚
â”‚  â”‚    - useExport â†’ Export data to CSV              â”‚  â”‚
â”‚  â”‚                                                   â”‚  â”‚
â”‚  â”‚  Works with:                                     â”‚  â”‚
â”‚  â”‚    - useCreate â†’ Single record creation          â”‚  â”‚
â”‚  â”‚    - useCreateMany â†’ Batch creation              â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Hook nÃ y cÃ³ má»¥c Ä‘Ã­ch:**

> **Import CSV files to backend - Parse, transform, batch process, and track progress**

### 1.2 Complete Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  USEIMPORT COMPLETE FLOW                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 1: User Prepares CSV File                             â”‚
â”‚                                                              â”‚
â”‚  CSV File (products.csv):                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ name,price,category,stock                              â”‚ â”‚
â”‚  â”‚ "Product A",99.99,"Electronics",50                     â”‚ â”‚
â”‚  â”‚ "Product B",49.99,"Clothing",100                       â”‚ â”‚
â”‚  â”‚ "Product C",29.99,"Books",75                           â”‚ â”‚
â”‚  â”‚ ...                                                     â”‚ â”‚
â”‚  â”‚ (1000 rows)                                             â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 2: Setup Hook with Options                            â”‚
â”‚                                                              â”‚
â”‚  const { inputProps, isLoading, mutationResult } =          â”‚
â”‚    useImport({                                               â”‚
â”‚      resource: "products",                                   â”‚
â”‚      batchSize: 10, // 10 records per batch                 â”‚
â”‚      mapData: (item) => ({                                   â”‚
â”‚        name: item.name,                                      â”‚
â”‚        price: parseFloat(item.price),                        â”‚
â”‚        category: item.category,                              â”‚
â”‚        stock: parseInt(item.stock),                          â”‚
â”‚      }),                                                     â”‚
â”‚      onProgress: ({ totalAmount, processedAmount }) => {     â”‚
â”‚        const percent = (processedAmount/totalAmount) * 100;  â”‚
â”‚        console.log(`${percent}% completed`);                 â”‚
â”‚      },                                                      â”‚
â”‚      onFinish: ({ succeeded, errored }) => {                 â”‚
â”‚        console.log(`Success: ${succeeded.length}`);          â”‚
â”‚        console.log(`Failed: ${errored.length}`);             â”‚
â”‚      }                                                       â”‚
â”‚    });                                                       â”‚
â”‚                                                              â”‚
â”‚  <input {...inputProps} /> // File input ready! âœ…          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 3: User Selects File                                  â”‚
â”‚                                                              â”‚
â”‚  <input type="file" accept=".csv" />                        â”‚
â”‚  â†“                                                           â”‚
â”‚  User clicks "Browse" â†’ Selects products.csv                â”‚
â”‚  â†“                                                           â”‚
â”‚  onChange event fires                                       â”‚
â”‚  â†“                                                           â”‚
â”‚  handleChange({ file: products.csv })                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 4: Parse CSV with PapaParse                           â”‚
â”‚                                                              â”‚
â”‚  papaparse.parse(file, {                                     â”‚
â”‚    complete: ({ data }) => {                                 â”‚
â”‚      // data = [                                             â”‚
â”‚      //   ["name", "price", "category", "stock"],           â”‚
â”‚      //   ["Product A", "99.99", "Electronics", "50"],      â”‚
â”‚      //   ["Product B", "49.99", "Clothing", "100"],        â”‚
â”‚      //   ...                                                â”‚
â”‚      // ]                                                    â”‚
â”‚    }                                                         â”‚
â”‚  });                                                         â”‚
â”‚                                                              â”‚
â”‚  Raw 2D array from CSV âœ…                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 5: Transform with importCSVMapper                     â”‚
â”‚                                                              â”‚
â”‚  const values = importCSVMapper(data, mapData);             â”‚
â”‚                                                              â”‚
â”‚  Internal process:                                           â”‚
â”‚  1. Extract headers: ["name", "price", "category", "stock"] â”‚
â”‚  2. Extract rows: [                                          â”‚
â”‚       ["Product A", "99.99", "Electronics", "50"],          â”‚
â”‚       ["Product B", "49.99", "Clothing", "100"],            â”‚
â”‚       ...                                                    â”‚
â”‚     ]                                                        â”‚
â”‚  3. Zip headers with each row:                              â”‚
â”‚     {                                                        â”‚
â”‚       name: "Product A",                                     â”‚
â”‚       price: "99.99",                                        â”‚
â”‚       category: "Electronics",                               â”‚
â”‚       stock: "50"                                            â”‚
â”‚     }                                                        â”‚
â”‚  4. Apply mapData to each object:                           â”‚
â”‚     {                                                        â”‚
â”‚       name: "Product A",                                     â”‚
â”‚       price: 99.99,        // â† Parsed!                     â”‚
â”‚       category: "Electronics",                               â”‚
â”‚       stock: 50            // â† Parsed!                     â”‚
â”‚     }                                                        â”‚
â”‚                                                              â”‚
â”‚  Result: Array of 1000 clean objects âœ…                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 6: Create Batches (Chunking)                          â”‚
â”‚                                                              â”‚
â”‚  batchSize = 10                                              â”‚
â”‚  values.length = 1000                                        â”‚
â”‚                                                              â”‚
â”‚  chunks = chunk(values, 10)                                  â”‚
â”‚  // [                                                        â”‚
â”‚  //   [item1, item2, ..., item10],   // Batch 1             â”‚
â”‚  //   [item11, item12, ..., item20], // Batch 2             â”‚
â”‚  //   ...                                                    â”‚
â”‚  //   [item991, ..., item1000]       // Batch 100           â”‚
â”‚  // ]                                                        â”‚
â”‚                                                              â”‚
â”‚  Total batches: 100 âœ…                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 7: Sequential Processing                              â”‚
â”‚                                                              â”‚
â”‚  for each batch (sequentially):                             â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚    â”‚ Batch 1: [item1...item10]                          â”‚  â”‚
â”‚    â”‚ â†“                                                   â”‚  â”‚
â”‚    â”‚ createMany.mutateAsync({                           â”‚  â”‚
â”‚    â”‚   resource: "products",                            â”‚  â”‚
â”‚    â”‚   values: [item1...item10]                         â”‚  â”‚
â”‚    â”‚ })                                                  â”‚  â”‚
â”‚    â”‚ â†“                                                   â”‚  â”‚
â”‚    â”‚ POST /products (bulk insert 10 records)            â”‚  â”‚
â”‚    â”‚ â†“                                                   â”‚  â”‚
â”‚    â”‚ Server: Success! Created 10 records                â”‚  â”‚
â”‚    â”‚ â†“                                                   â”‚  â”‚
â”‚    â”‚ Update progress: 10/1000 (1%) âœ…                   â”‚  â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                              â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚    â”‚ Batch 2: [item11...item20]                         â”‚  â”‚
â”‚    â”‚ â†“                                                   â”‚  â”‚
â”‚    â”‚ createMany.mutateAsync(...)                        â”‚  â”‚
â”‚    â”‚ â†“                                                   â”‚  â”‚
â”‚    â”‚ POST /products                                      â”‚  â”‚
â”‚    â”‚ â†“                                                   â”‚  â”‚
â”‚    â”‚ Update progress: 20/1000 (2%) âœ…                   â”‚  â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                              â”‚
â”‚    ... (continue for all 100 batches)                       â”‚
â”‚                                                              â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚    â”‚ Batch 100: [item991...item1000]                    â”‚  â”‚
â”‚    â”‚ â†“                                                   â”‚  â”‚
â”‚    â”‚ Update progress: 1000/1000 (100%) âœ…               â”‚  â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                              â”‚
â”‚  Why sequential?                                             â”‚
â”‚  â†’ Prevents server overload                                 â”‚
â”‚  â†’ Easier error tracking                                    â”‚
â”‚  â†’ Predictable progress                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 8: Error Handling                                     â”‚
â”‚                                                              â”‚
â”‚  If batch fails:                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Batch 5: Error! Server validation failed              â”‚ â”‚
â”‚  â”‚ â†“                                                       â”‚ â”‚
â”‚  â”‚ Catch error                                             â”‚ â”‚
â”‚  â”‚ â†“                                                       â”‚ â”‚
â”‚  â”‚ Record as "errored":                                    â”‚ â”‚
â”‚  â”‚ {                                                       â”‚ â”‚
â”‚  â”‚   type: "error",                                        â”‚ â”‚
â”‚  â”‚   request: [item41...item50],  // Failed items        â”‚ â”‚
â”‚  â”‚   response: [error]             // Error object        â”‚ â”‚
â”‚  â”‚ }                                                       â”‚ â”‚
â”‚  â”‚ â†“                                                       â”‚ â”‚
â”‚  â”‚ Continue to next batch! (Don't stop!) âœ…              â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                              â”‚
â”‚  Resilient: Continues even if some batches fail! âœ…        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 9: Finish & Callback                                  â”‚
â”‚                                                              â”‚
â”‚  All batches processed!                                      â”‚
â”‚                                                              â”‚
â”‚  Results:                                                    â”‚
â”‚  {                                                           â”‚
â”‚    succeeded: [                                              â”‚
â”‚      { type: "success", request: [...], response: [...] },  â”‚
â”‚      { type: "success", request: [...], response: [...] },  â”‚
â”‚      ... (95 successful batches)                            â”‚
â”‚    ],                                                        â”‚
â”‚    errored: [                                                â”‚
â”‚      { type: "error", request: [...], response: [error] },  â”‚
â”‚      ... (5 failed batches)                                 â”‚
â”‚    ]                                                         â”‚
â”‚  }                                                           â”‚
â”‚                                                              â”‚
â”‚  onFinish({ succeeded, errored })                           â”‚
â”‚  â†“                                                           â”‚
â”‚  User sees summary:                                          â”‚
â”‚  "Successfully imported 950 products"                        â”‚
â”‚  "Failed to import 50 products"                              â”‚
â”‚  âœ… Import complete!                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 2. DESIGN PATTERNS - GIáº¢I THÃCH CHO NGÆ¯á»œI Má»šI

> **File index.tsx: 321 dÃ²ng** - CSV import with batch processing!

---

### 2.1 Sequential Processing Pattern - One at a Time

#### ğŸš¦ VÃ Dá»¤ Äá»œI THÆ¯á»œNG: Traffic Light

```
Processing Requests:

PARALLEL (All at once):
â†’ Send 100 batches simultaneously
â†’ Server: 100 concurrent requests! ğŸ’¥
â†’ Server overload! âŒ
â†’ Some fail, some succeed
â†’ Hard to track! âŒ

SEQUENTIAL (One by one):
â†’ Send batch 1 â†’ Wait â†’ Complete âœ…
â†’ Send batch 2 â†’ Wait â†’ Complete âœ…
â†’ Send batch 3 â†’ Wait â†’ Complete âœ…
â†’ ...
â†’ Send batch 100 â†’ Wait â†’ Complete âœ…
â†’ Server: 1 request at a time âœ…
â†’ Easy to track progress! âœ…

useImport = Traffic light!
â†’ One batch at a time
â†’ Wait for completion
â†’ Then next batch! âœ…
```

**Sequential Processing Pattern** = Process items one by one, not in parallel

#### Implementation:

```typescript
// From index.tsx (lines 224-244) and sequentialPromises

// Helper function: sequentialPromises
export const sequentialPromises = async (
  promises: (() => Promise<any>)[],
  onEachResolve: (result, index) => any,
  onEachReject: (error, index) => any,
) => {
  const results = [];

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // KEY: for...of loop (NOT Promise.all!)
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  for (const [index, promise] of promises.entries()) {
    // â†‘ Process ONE at a time

    try {
      const result = await promise(); // â† WAIT for completion!
      // â†‘ Next iteration only after this completes

      results.push(onEachResolve(result, index));
    } catch (error) {
      results.push(onEachReject(error, index));
    }
  }

  return results;
};

// Usage in useImport:
const chunkedFns = chunks.map((chunkedValues) => {
  const fn = async () => {
    return await createMany.mutateAsync({
      resource: identifier ?? "",
      values: chunkedValues,
      // ... options
    });
  };
  return fn;
});

// Sequential execution
const createdValues = await sequentialPromises(
  chunkedFns,
  // â†‘ Array of functions that return promises
  ({ response, currentBatchLength }) => {
    // Success handler
    setProcessedAmount((prev) => prev + currentBatchLength);
    return { type: "success", response, ... };
  },
  (error, index) => {
    // Error handler
    return { type: "error", response: [error], ... };
  },
);
```

#### Why Sequential vs Parallel?

```typescript
// PARALLEL (bad for import):
await Promise.all([
  createMany(batch1),
  createMany(batch2),
  createMany(batch3),
  // ... 100 batches
]); // â† 100 concurrent requests! âŒ

// Problems:
// - Server overload (100 simultaneous connections)
// - Memory issues (all responses in memory)
// - Hard to track which batch failed
// - Progress unclear

// SEQUENTIAL (good for import):
for (const batch of batches) {
  await createMany(batch); // â† One at a time âœ…
  updateProgress();
}

// Benefits:
// - Server friendly (1 connection at a time)
// - Low memory (process one batch at a time)
// - Easy error tracking (know exact batch)
// - Clear progress (1/100, 2/100, ...)
```

#### Real Example - Upload Progress:

```tsx
function ImportButton() {
  const { inputProps, isLoading } = useImport({
    batchSize: 50,
    onProgress: ({ totalAmount, processedAmount }) => {
      console.log(`Batch ${processedAmount}/${totalAmount}`);
      // Sequential â†’ Predictable progress! âœ…
      // Batch 1/100 â†’ 2/100 â†’ 3/100 â†’ ...
    },
  });

  return (
    <div>
      <input {...inputProps} />
      {isLoading && <ProgressBar />}
    </div>
  );
}
```

#### ğŸ’¡ Táº I SAO quan trá»ng?

- âœ… **Server Friendly** - No overload
- âœ… **Predictable** - Clear progress tracking
- âœ… **Error Tracking** - Know exactly which batch failed
- âœ… **Memory Efficient** - Process one batch at a time

---

### 2.2 Chunking Pattern - Batch Processing

#### ğŸ“¦ VÃ Dá»¤ Äá»œI THÆ¯á»œNG: Loading Truck

```
Moving 1000 Boxes:

ONE BY ONE (batchSize=1):
â†’ Trip 1: 1 box
â†’ Trip 2: 1 box
â†’ Trip 3: 1 box
â†’ ...
â†’ Trip 1000: 1 box
â†’ 1000 trips! âŒ Inefficient!

ALL AT ONCE (batchSize=1000):
â†’ Trip 1: 1000 boxes
â†’ Truck too heavy! ğŸ’¥
â†’ Crashes! âŒ

BATCHES (batchSize=10):
â†’ Trip 1: 10 boxes âœ…
â†’ Trip 2: 10 boxes âœ…
â†’ ...
â†’ Trip 100: 10 boxes âœ…
â†’ 100 trips! Perfect! âœ…

useImport chunking = Loading truck!
â†’ Configurable batch size
â†’ Balance efficiency & safety âœ…
```

**Chunking Pattern** = Split large array into smaller chunks

#### Implementation:

```typescript
// From index.tsx (lines 248-270)

import chunk from "lodash/chunk";

// Step 1: Split values into chunks
const chunks = chunk(values, batchSize);
// â†‘ lodash chunk utility

// Example:
values = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]; // 10 items
batchSize = 3;

chunks = chunk(values, 3);
// [
//   [1, 2, 3],      // Chunk 1
//   [4, 5, 6],      // Chunk 2
//   [7, 8, 9],      // Chunk 3
//   [10]            // Chunk 4 (smaller)
// ]

// Step 2: Create function for each chunk
const chunkedFns = chunks.map((chunkedValues) => {
  const fn = async () => {
    const response = await createMany.mutateAsync({
      resource: identifier ?? "",
      values: chunkedValues, // â† Entire chunk!
      // ...
    });

    return {
      response,
      value: chunkedValues,
      currentBatchLength: chunkedValues.length,
    };
  };

  return fn;
});

// Step 3: Process chunks sequentially
await sequentialPromises(chunkedFns, onSuccess, onError);
```

#### Batch Size Strategies:

```typescript
// STRATEGY 1: Single (batchSize=1)
const { inputProps } = useImport({
  batchSize: 1,
});

// Flow:
// â†’ Uses useCreate (not useCreateMany)
// â†’ POST /products (1 record)
// â†’ POST /products (1 record)
// â†’ ... 1000 times
// â†’ Slowest but most compatible

// STRATEGY 2: Small batches (batchSize=10)
const { inputProps } = useImport({
  batchSize: 10,
});

// Flow:
// â†’ Uses useCreateMany
// â†’ POST /products (10 records)
// â†’ POST /products (10 records)
// â†’ ... 100 times
// â†’ Good balance

// STRATEGY 3: Large batches (batchSize=100)
const { inputProps } = useImport({
  batchSize: 100,
});

// Flow:
// â†’ Uses useCreateMany
// â†’ POST /products (100 records)
// â†’ ... 10 times
// â†’ Fastest but risk of timeout

// STRATEGY 4: All at once (batchSize=Number.MAX_SAFE_INTEGER)
const { inputProps } = useImport({
  batchSize: Number.MAX_SAFE_INTEGER, // Default!
});

// Flow:
// â†’ POST /products (ALL 1000 records)
// â†’ 1 request total
// â†’ Fastest but high risk
```

#### Choosing Batch Size:

```
Small dataset (< 100 items):
â†’ batchSize = 50-100 or MAX_SAFE_INTEGER
â†’ Fast, low risk

Medium dataset (100-1000 items):
â†’ batchSize = 10-50
â†’ Good balance

Large dataset (> 1000 items):
â†’ batchSize = 10-20
â†’ Safer, slower
â†’ Better progress tracking

Server limits:
â†’ Check backend max payload size
â†’ Adjust batchSize accordingly
```

#### ğŸ’¡ Táº I SAO quan trá»ng?

- âœ… **Efficiency** - Fewer requests than one-by-one
- âœ… **Safety** - Smaller than all-at-once
- âœ… **Flexibility** - Configurable for different needs
- âœ… **Progress** - Track batch completion

---

### 2.3 Mapper Pattern - Data Transformation

#### ğŸ”„ VÃ Dá»¤ Äá»œI THÆ¯á»œNG: Airport Customs

```
Importing Goods:

RAW (from CSV):
â†’ Prices as strings: "99.99"
â†’ Quantities as strings: "50"
â†’ Dates as strings: "2024-01-01"
â†’ Can't use directly! âŒ

PROCESSED (after mapper):
â†’ Prices as numbers: 99.99 âœ…
â†’ Quantities as integers: 50 âœ…
â†’ Dates as Date objects: new Date(...) âœ…
â†’ Ready to use! âœ…

mapData = Customs officer!
â†’ Inspects each item
â†’ Converts to proper format
â†’ Ready for backend! âœ…
```

**Mapper Pattern** = Transform data structure

#### Implementation:

```typescript
// From index.tsx (lines 130, 202) and importCSVMapper

// Step 1: importCSVMapper helper
export const importCSVMapper = (data: any[][], mapData: Function) => {
  const [headers, ...body] = data;
  // â†‘ Extract first row as headers

  return (
    body
      .map((entry) => fromPairs(zip(headers, entry)))
      // â†‘ Zip headers with each row to create objects

      .map((item, index, array) => mapData(item, index, array))
  );
  // â†‘ Apply user's transformation
};

// Example transformation:
// Input CSV:
// [
//   ["name", "price", "stock"],        // Headers
//   ["Product A", "99.99", "50"],      // Row 1
//   ["Product B", "49.99", "100"],     // Row 2
// ]

// After zip:
// [
//   { name: "Product A", price: "99.99", stock: "50" },
//   { name: "Product B", price: "49.99", stock: "100" },
// ]

// After mapData:
const { inputProps } = useImport({
  mapData: (item) => ({
    name: item.name,
    price: parseFloat(item.price), // â† String to number!
    stock: parseInt(item.stock), // â† String to integer!
    available: parseInt(item.stock) > 0, // â† Computed field!
  }),
});

// Result:
// [
//   { name: "Product A", price: 99.99, stock: 50, available: true },
//   { name: "Product B", price: 49.99, stock: 100, available: true },
// ]
```

#### Common Transformations:

```typescript
const { inputProps } = useImport({
  mapData: (item, index) => ({
    // TYPE CONVERSIONS:
    price: parseFloat(item.price), // String â†’ Number
    stock: parseInt(item.stock, 10), // String â†’ Integer
    active: item.active === "true", // String â†’ Boolean
    tags: item.tags.split(","), // String â†’ Array

    // DATE PARSING:
    createdAt: new Date(item.createdAt), // String â†’ Date

    // COMPUTED FIELDS:
    total: parseFloat(item.price) * parseInt(item.stock),
    index: index + 1, // Row number

    // VALIDATION:
    status: item.stock > 0 ? "available" : "out_of_stock",

    // RENAMING:
    productName: item.name, // name â†’ productName

    // DEFAULTS:
    category: item.category || "Uncategorized",

    // CLEANING:
    description: item.description?.trim(),
  }),
});
```

#### Real Example - E-commerce Import:

```tsx
function ProductImport() {
  const { inputProps, isLoading } = useImport({
    resource: "products",
    mapData: (item, index) => ({
      // Required fields
      sku: item.sku.toUpperCase().trim(),
      name: item.name.trim(),

      // Type conversions
      price: parseFloat(item.price) || 0,
      cost: parseFloat(item.cost) || 0,
      stock: parseInt(item.stock, 10) || 0,

      // Computed fields
      profit: parseFloat(item.price) - parseFloat(item.cost),
      margin:
        ((parseFloat(item.price) - parseFloat(item.cost)) /
          parseFloat(item.price)) *
        100,

      // Categories (comma-separated to array)
      categories: item.categories?.split(",").map((c) => c.trim()) || [],

      // Boolean conversions
      featured: item.featured?.toLowerCase() === "true",
      active: item.active?.toLowerCase() !== "false", // Default true

      // Date parsing
      launchDate: item.launchDate ? new Date(item.launchDate) : new Date(),

      // Validation
      status: parseInt(item.stock) > 0 ? "in_stock" : "out_of_stock",

      // Metadata
      importedAt: new Date(),
      importBatch: `batch-${Date.now()}`,
      rowNumber: index + 1,
    }),
  });

  return <input {...inputProps} disabled={isLoading} />;
}
```

#### ğŸ’¡ Táº I SAO quan trá»ng?

- âœ… **Type Safety** - Convert strings to proper types
- âœ… **Validation** - Clean and validate data
- âœ… **Enrichment** - Add computed fields
- âœ… **Flexibility** - Transform however needed

---

### 2.4 Progress Tracking Pattern - Observable Progress

#### ğŸ“Š VÃ Dá»¤ Äá»œI THÆ¯á»œNG: Pizza Delivery Tracker

```
Pizza Delivery:

NO TRACKING (bad):
â†’ Order pizza
â†’ Wait...
â†’ Is it coming? ğŸ¤·
â†’ No idea! âŒ

WITH TRACKING (good):
â†’ Order pizza
â†’ Preparing (25%) ğŸ•
â†’ Baking (50%) ğŸ”¥
â†’ Out for delivery (75%) ğŸš—
â†’ Delivered (100%) âœ…
â†’ Always know status! âœ…

useImport progress = Pizza tracker!
â†’ onProgress callback
â†’ Real-time updates
â†’ Show progress bar! âœ…
```

**Progress Tracking Pattern** = Observable progress updates

#### Implementation:

```typescript
// From index.tsx (lines 192-194, 227-229, 274-277)

// State for tracking
const [processedAmount, setProcessedAmount] = useState<number>(0);
const [totalAmount, setTotalAmount] = useState<number>(0);

// Update total when parsing completes
const values = importCSVMapper(data, mapData);
setTotalAmount(values.length); // â† Total items

// Update processed after each batch
await sequentialPromises(
  chunkedFns,
  ({ response, currentBatchLength }) => {
    // After each successful batch:
    setProcessedAmount((prev) => prev + currentBatchLength);
    // â†‘ Increment by batch size

    return { type: "success", ... };
  },
);

// Notify user via useEffect
useEffect(() => {
  onProgress?.({ totalAmount, processedAmount });
  // â†‘ Callback on every update
}, [totalAmount, processedAmount]);
```

#### Progress Calculation:

```typescript
const { inputProps, isLoading } = useImport({
  batchSize: 10,
  onProgress: ({ totalAmount, processedAmount }) => {
    // Calculate percentage
    const percentage = (processedAmount / totalAmount) * 100;

    // Calculate remaining
    const remaining = totalAmount - processedAmount;

    // Estimate time (if tracked)
    const itemsPerSecond = processedAmount / elapsedSeconds;
    const remainingSeconds = remaining / itemsPerSecond;

    console.log({
      total: totalAmount, // 1000
      processed: processedAmount, // 350
      percentage: percentage.toFixed(1), // "35.0%"
      remaining, // 650
      eta: `${remainingSeconds}s`, // "180s"
    });
  },
});
```

#### Real Example - Progress Bar UI:

```tsx
function ImportWithProgress() {
  const [progress, setProgress] = useState(0);
  const [status, setStatus] = useState<string>("idle");

  const { inputProps, isLoading } = useImport({
    resource: "products",
    batchSize: 50,

    onProgress: ({ totalAmount, processedAmount }) => {
      const percent = Math.floor((processedAmount / totalAmount) * 100);
      setProgress(percent);

      if (percent < 100) {
        setStatus(`Importing... ${processedAmount}/${totalAmount}`);
      }
    },

    onFinish: ({ succeeded, errored }) => {
      setProgress(100);
      setStatus(
        `Complete! Success: ${succeeded.length}, Failed: ${errored.length}`,
      );
    },
  });

  return (
    <div>
      <input {...inputProps} disabled={isLoading} />

      {isLoading && (
        <div className="progress-container">
          <div className="progress-bar" style={{ width: `${progress}%` }}>
            {progress}%
          </div>
          <p>{status}</p>
        </div>
      )}
    </div>
  );
}
```

#### ğŸ’¡ Táº I SAO quan trá»ng?

- âœ… **User Feedback** - Show import progress
- âœ… **ETA Estimation** - Calculate remaining time
- âœ… **Transparency** - User knows what's happening
- âœ… **Confidence** - Not just a spinner

---

### 2.5 Error Recovery Pattern - Resilient Processing

#### ğŸ›¡ï¸ VÃ Dá»¤ Äá»œI THÆ¯á»œNG: Assembly Line

```
Manufacturing Products:

FAIL-FAST (bad):
â†’ Process item 1: OK âœ…
â†’ Process item 2: OK âœ…
â†’ Process item 3: DEFECT! âŒ
â†’ STOP ENTIRE LINE! ğŸ’¥
â†’ Items 4-100 not processed! âŒ

FAIL-RESILIENT (good):
â†’ Process item 1: OK âœ…
â†’ Process item 2: OK âœ…
â†’ Process item 3: DEFECT! âŒ
â†’ Mark as defective
â†’ CONTINUE LINE! âœ…
â†’ Process items 4-100 âœ…
â†’ Report defects at end âœ…

useImport = Resilient assembly!
â†’ One batch fails?
â†’ Continue with rest! âœ…
```

**Error Recovery Pattern** = Continue processing despite errors

#### Implementation:

```typescript
// From sequentialPromises (lines 22-29)

for (const [index, promise] of promises.entries()) {
  try {
    const result = await promise();
    results.push(onEachResolve(result, index));
    // â†‘ Success: Add to results
  } catch (error) {
    results.push(onEachReject(error, index));
    // â†‘ Error: Still add to results! Don't throw!
    // â†‘ Continue to next iteration! âœ…
  }
}
// â†‘ ALL batches processed, regardless of errors!

// Usage:
await sequentialPromises(
  chunkedFns,
  (response) => {
    // Success handler
    return {
      type: "success",
      response: response.data,
      request: values,
    };
  },
  (error, index) => {
    // Error handler - NOT thrown, just recorded!
    return {
      type: "error",
      response: [error],
      request: chunks[index],
    };
  },
);
```

#### Error Handling Flow:

```typescript
// Scenario: Importing 100 batches, batch 5 fails

// Batch 1: Success â†’ { type: "success", ... }
// Batch 2: Success â†’ { type: "success", ... }
// Batch 3: Success â†’ { type: "success", ... }
// Batch 4: Success â†’ { type: "success", ... }
// Batch 5: ERROR! â†’ { type: "error", response: [error], request: [...] }
//   â†‘ Caught! Recorded! Continue! âœ…
// Batch 6: Success â†’ { type: "success", ... }
// Batch 7: Success â†’ { type: "success", ... }
// ...
// Batch 100: Success â†’ { type: "success", ... }

// Final result:
{
  succeeded: 99 batches,  // âœ…
  errored: 1 batch        // âŒ
}
```

#### Real Example - Error Reporting:

```tsx
function ImportWithErrorHandling() {
  const [errors, setErrors] = useState<any[]>([]);

  const { inputProps } = useImport({
    resource: "products",
    batchSize: 10,

    onFinish: ({ succeeded, errored }) => {
      if (errored.length > 0) {
        // Extract failed items
        const failedItems = errored.flatMap((e) => e.request);
        setErrors(failedItems);

        // Show summary
        toast.error(
          `Import complete! ${succeeded.length} succeeded, ${errored.length} failed`,
        );

        // Optionally download failed items
        const csv = generateCSV(failedItems);
        downloadCSV(csv, "failed-items.csv");
      } else {
        toast.success(`All ${succeeded.length} items imported!`);
      }
    },
  });

  return (
    <div>
      <input {...inputProps} />

      {errors.length > 0 && (
        <div className="errors">
          <h3>Failed Items ({errors.length})</h3>
          <ul>
            {errors.map((item, i) => (
              <li key={i}>
                {item.name}: {item.error}
              </li>
            ))}
          </ul>
          <button onClick={() => retryFailed(errors)}>Retry Failed</button>
        </div>
      )}
    </div>
  );
}
```

#### ğŸ’¡ Táº I SAO quan trá»ng?

- âœ… **Resilience** - Don't fail entire import
- âœ… **Partial Success** - Import what can be imported
- âœ… **Error Reporting** - Know what failed
- âœ… **Retry** - Can retry just failed items

---

## ğŸ“ TÃ“M Táº®T DESIGN PATTERNS

| Pattern               | VÃ­ dá»¥ Ä‘á»i thÆ°á»ng | Giáº£i quyáº¿t váº¥n Ä‘á» gÃ¬    | Trong useImport                |
| --------------------- | ---------------- | ----------------------- | ------------------------------ |
| **Sequential**        | Traffic light    | Process one at a time   | Prevent server overload        |
| **Chunking**          | Loading truck    | Batch processing        | Configurable batch sizes       |
| **Mapper**            | Airport customs  | Data transformation     | CSV â†’ Clean objects            |
| **Progress Tracking** | Pizza tracker    | Observable progress     | Real-time progress updates     |
| **Error Recovery**    | Assembly line    | Continue despite errors | Partial success, error reports |

---

## 3. KEY FEATURES

### 3.1 Configurable Batch Size

```typescript
// Single record at a time
const single = useImport({ batchSize: 1 });

// Small batches
const small = useImport({ batchSize: 10 });

// All at once (default)
const allAtOnce = useImport({ batchSize: Number.MAX_SAFE_INTEGER });
```

### 3.2 Progress Tracking

```typescript
const { inputProps } = useImport({
  onProgress: ({ totalAmount, processedAmount }) => {
    const percent = (processedAmount / totalAmount) * 100;
    console.log(`${percent.toFixed(1)}% complete`);
  },
});
```

### 3.3 Error Handling & Reporting

```typescript
const { inputProps } = useImport({
  onFinish: ({ succeeded, errored }) => {
    console.log(`âœ… Success: ${succeeded.length}`);
    console.log(`âŒ Failed: ${errored.length}`);

    // Download failed items for retry
    if (errored.length > 0) {
      const failedItems = errored.flatMap((e) => e.request);
      downloadFailedCSV(failedItems);
    }
  },
});
```

### 3.4 Data Transformation

```typescript
const { inputProps } = useImport({
  mapData: (item) => ({
    name: item.name.trim(),
    price: parseFloat(item.price),
    stock: parseInt(item.stock, 10),
    active: item.active !== "false",
  }),
});
```

### 3.5 Input Props Binding

```typescript
const { inputProps } = useImport();

// Spread directly to input element
<input {...inputProps} />;
// Automatically configured:
// - type="file"
// - accept=".csv"
// - onChange handler
```

---

## 4. COMMON USE CASES

### 4.1 Basic CSV Import

```tsx
function ProductImport() {
  const { inputProps, isLoading } = useImport({
    resource: "products",
  });

  return (
    <div>
      <input {...inputProps} disabled={isLoading} />
      {isLoading && <p>Importing...</p>}
    </div>
  );
}
```

### 4.2 Import with Progress Bar

```tsx
function ImportWithProgress() {
  const [progress, setProgress] = useState(0);

  const { inputProps } = useImport({
    resource: "products",
    batchSize: 50,
    onProgress: ({ totalAmount, processedAmount }) => {
      setProgress((processedAmount / totalAmount) * 100);
    },
  });

  return (
    <div>
      <input {...inputProps} />
      <progress value={progress} max={100} />
      <span>{progress.toFixed(0)}%</span>
    </div>
  );
}
```

### 4.3 Import with Data Transformation

```tsx
function UserImport() {
  const { inputProps } = useImport({
    resource: "users",
    mapData: (item) => ({
      firstName: item["First Name"],
      lastName: item["Last Name"],
      email: item.Email.toLowerCase(),
      age: parseInt(item.Age, 10),
      premium: item.Premium === "yes",
      registeredAt: new Date(item["Registration Date"]),
    }),
  });

  return <input {...inputProps} />;
}
```

### 4.4 Import with Error Handling

```tsx
function ImportWithErrors() {
  const [summary, setSummary] = useState<string>("");

  const { inputProps } = useImport({
    resource: "products",
    onFinish: ({ succeeded, errored }) => {
      const total = succeeded.length + errored.length;
      setSummary(
        `Imported ${total} items: ${succeeded.length} succeeded, ${errored.length} failed`,
      );

      if (errored.length > 0) {
        console.error("Failed items:", errored);
      }
    },
  });

  return (
    <div>
      <input {...inputProps} />
      {summary && <div className="summary">{summary}</div>}
    </div>
  );
}
```

### 4.5 Large File Import with Batching

```tsx
function BulkImport() {
  const [stats, setStats] = useState({ total: 0, processed: 0 });

  const { inputProps, isLoading } = useImport({
    resource: "products",
    batchSize: 100, // Large batches for efficiency

    onProgress: ({ totalAmount, processedAmount }) => {
      setStats({ total: totalAmount, processed: processedAmount });
    },

    onFinish: ({ succeeded, errored }) => {
      toast.success(
        `Import complete! ${succeeded.length}/${
          succeeded.length + errored.length
        } items`,
      );
    },
  });

  return (
    <div>
      <input {...inputProps} disabled={isLoading} />
      {isLoading && (
        <div>
          Processing: {stats.processed} / {stats.total}
        </div>
      )}
    </div>
  );
}
```

### 4.6 Manual Trigger (Not Auto-upload)

```tsx
function ManualImport() {
  const [file, setFile] = useState<File | null>(null);

  const { handleChange, isLoading } = useImport({
    resource: "products",
  });

  const handleFileSelect = (e: React.ChangeEvent<HTMLInputElement>) => {
    if (e.target.files?.[0]) {
      setFile(e.target.files[0]);
    }
  };

  const handleImport = async () => {
    if (file) {
      await handleChange({ file });
    }
  };

  return (
    <div>
      <input type="file" accept=".csv" onChange={handleFileSelect} />
      <button onClick={handleImport} disabled={!file || isLoading}>
        {isLoading ? "Importing..." : "Import File"}
      </button>
    </div>
  );
}
```

---

## 5. ARCHITECTURE DECISIONS

### 5.1 Why Sequential vs Parallel?

**Answer:** Server stability and progress tracking

```
Parallel (rejected):
â†’ All batches at once
â†’ Server overload risk
â†’ Hard to track progress
â†’ Memory intensive

Sequential (chosen):
â†’ One batch at a time
â†’ Server friendly
â†’ Clear progress
â†’ Low memory footprint
```

### 5.2 Why Default batchSize = MAX_SAFE_INTEGER?

**Answer:** Best performance when supported

```
When createMany supported:
â†’ Send all in one request
â†’ Fastest import
â†’ Fewest network calls

When createMany not supported:
â†’ Set batchSize=1
â†’ Falls back to create
â†’ Still works, just slower
```

### 5.3 Why Continue on Error?

**Answer:** Partial success better than total failure

```
Fail-fast (rejected):
â†’ One error stops all
â†’ Lose all progress
â†’ Must restart from scratch

Fail-resilient (chosen):
â†’ Error recorded
â†’ Continue processing
â†’ Partial success
â†’ Can retry failed items
```

### 5.4 Why PapaParse Library?

**Answer:** Robust CSV parsing

```
Manual parsing (rejected):
â†’ Handle edge cases
â†’ Quote handling
â†’ Escape characters
â†’ Different encodings
â†’ Too complex!

PapaParse (chosen):
â†’ Industry standard
â†’ Handles all edge cases
â†’ Configurable
â†’ Well-tested
```

### 5.5 Why Return inputProps?

**Answer:** Convenience and consistency

```
Without inputProps:
â†’ User must configure manually
â†’ type="file"
â†’ accept=".csv"
â†’ onChange handler
â†’ Boilerplate!

With inputProps:
â†’ <input {...inputProps} />
â†’ One line!
â†’ Consistent API
```

---

## 6. COMMON PITFALLS

### 6.1 Not Handling Loading State

```typescript
// âŒ WRONG
const { inputProps } = useImport();
return <input {...inputProps} />;
// Input enabled during import! Multiple uploads!

// âœ… CORRECT
const { inputProps, isLoading } = useImport();
return <input {...inputProps} disabled={isLoading} />;
```

### 6.2 Forgetting mapData for Type Conversion

```typescript
// âŒ WRONG
const { inputProps } = useImport();
// CSV: "99.99" (string)
// Backend expects: 99.99 (number)
// Type mismatch error! âŒ

// âœ… CORRECT
const { inputProps } = useImport({
  mapData: (item) => ({
    price: parseFloat(item.price), // String â†’ Number
  }),
});
```

### 6.3 Using Large Batch Size Without createMany

```typescript
// âŒ WRONG
const { inputProps } = useImport({
  batchSize: 100, // Large batch
  // But dataProvider doesn't support createMany!
  // Error! âŒ
});

// âœ… CORRECT - Check backend support
const { inputProps } = useImport({
  batchSize: dataProvider.hasCreateMany ? 100 : 1,
});
```

### 6.4 Not Showing Progress

```typescript
// âŒ BAD - No feedback
const { inputProps, isLoading } = useImport();
return (
  <div>
    <input {...inputProps} />
    {isLoading && "Loading..."} {/* No progress! */}
  </div>
);

// âœ… GOOD - With progress
const [progress, setProgress] = useState(0);
const { inputProps, isLoading } = useImport({
  onProgress: ({ totalAmount, processedAmount }) => {
    setProgress((processedAmount / totalAmount) * 100);
  },
});
return (
  <div>
    <input {...inputProps} />
    {isLoading && `${progress.toFixed(0)}% complete`}
  </div>
);
```

### 6.5 Not Handling Errors

```typescript
// âŒ WRONG - Silent failure
const { inputProps } = useImport();
// Import fails â†’ User doesn't know!

// âœ… CORRECT - Error notification
const { inputProps } = useImport({
  onFinish: ({ succeeded, errored }) => {
    if (errored.length > 0) {
      toast.error(`${errored.length} items failed to import`);
    }
  },
});
```

---

## 7. PERFORMANCE CONSIDERATIONS

### 7.1 Batch Size Sweet Spot

```
Too small (batchSize=1):
â†’ Many API calls
â†’ Slow import
â†’ Network overhead

Too large (batchSize=1000):
â†’ Risk of timeout
â†’ Large payload
â†’ Server strain

Recommended: 10-50
â†’ Good balance
â†’ Fast enough
â†’ Safe enough
```

### 7.2 Sequential vs Parallel

```
Sequential (current):
â†’ 1 request at a time
â†’ Safe for server
â†’ Slower total time

Parallel (not implemented):
â†’ N requests at once
â†’ Risk server overload
â†’ Faster total time
â†’ Complex error handling
```

### 7.3 Memory Considerations

```
Small file (< 1000 rows):
â†’ batchSize = MAX_SAFE_INTEGER
â†’ One request
â†’ Fast

Large file (> 10000 rows):
â†’ batchSize = 10-50
â†’ Process in chunks
â†’ Lower memory
```

---

## 8. TESTING

```typescript
// From index.spec.tsx

describe("useImport", () => {
  it("should call onProgress", async () => {
    const onProgressMock = vi.fn();

    const { result } = renderHook(
      () =>
        useImport({
          batchSize: 1,
          onProgress: onProgressMock,
        }),
      { wrapper: TestWrapper({ dataProvider: MockJSONServer }) },
    );

    await act(async () => {
      await result.current.handleChange({ file: csvFile });
    });

    expect(onProgressMock).toHaveBeenCalledWith({
      totalAmount: 3,
      processedAmount: 3,
    });
  });

  it("should handle batch processing", async () => {
    const createManyMock = vi.fn();

    renderHook(
      () =>
        useImport({
          batchSize: 2, // 2 items per batch
        }),
      {
        wrapper: TestWrapper({
          dataProvider: {
            createMany: createManyMock,
          },
        }),
      },
    );

    // CSV has 3 items â†’ 2 batches
    expect(createManyMock).toHaveBeenCalledTimes(2);
  });
});
```

---

## 9. Káº¾T LUáº¬N

### Design Patterns Summary

- âœ… **Sequential**: Process batches one at a time
- âœ… **Chunking**: Split large imports into batches
- âœ… **Mapper**: Transform CSV data
- âœ… **Progress Tracking**: Observable import progress
- âœ… **Error Recovery**: Continue despite failures

### Key Features

1. **CSV Parsing** - PapaParse integration
2. **Batch Processing** - Configurable batch sizes
3. **Progress Tracking** - Real-time progress updates
4. **Error Handling** - Resilient processing
5. **Data Transformation** - mapData function
6. **Input Binding** - Convenient inputProps

### Khi nÃ o dÃ¹ng useImport?

âœ… **NÃªn dÃ¹ng:**

- Import CSV files to backend
- Bulk data creation
- Data migration
- User data uploads
- Initial system setup

âŒ **KhÃ´ng dÃ¹ng:**

- Export data (use useExport)
- Single record creation (use useCreate)
- Non-CSV formats (use custom logic)
- Real-time data sync (use live provider)

### Remember

âœ… **321 lines** - CSV import utility
ğŸš¦ **Sequential** - One batch at a time
ğŸ“¦ **Chunking** - Configurable batches
ğŸ”„ **Mapper** - Transform CSV data
ğŸ“Š **Progress** - Track import status
ğŸ›¡ï¸ **Resilient** - Continue on errors

---

> ğŸ“š **Best Practice**: Always use **mapData** to convert types (strings â†’ numbers). Set appropriate **batchSize** (10-50 recommended). Always show **progress** to user. Handle **errors** gracefully with onFinish. Use **sequential** processing to avoid server overload. Test with **large files** before production!
